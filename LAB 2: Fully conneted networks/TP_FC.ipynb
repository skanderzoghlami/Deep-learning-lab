{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_FC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wg_HWBXC8hQ"
      },
      "source": [
        "# Environement setup\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUwcBtHLWOJo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from numpy.random import multivariate_normal\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import LabelEncoder # will be used to label iris dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41_noy-eoQPW"
      },
      "source": [
        "# !pip install tensorflow==2.7.0\n",
        "# !pip install numpy==1.19.5\n",
        "# !pip install pandas==1.1.5\n",
        "# !pip install pandas-datareader==0.9.0\n",
        "# !pip install pandas-gbq==0.13.3\n",
        "# !pip install pandas-profiling==1.4.1\n",
        "# !pip install matplotlib==3.2.2\n",
        "# !pip install matplotlib-inline==0.1.3\n",
        "# !pip install matplotlib-venn==0.11.6\n",
        "# !pip install sklearn-pandas==1.8.0\n",
        "# !pip install sklearn==0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lCT2n7woX6K"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TElSoLvyDDVu"
      },
      "source": [
        "### Question 1: Gradient descient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkUMpa43c5Tr"
      },
      "source": [
        "def f(x):\n",
        "  return x*x - 1\n",
        "\n",
        "def f2(x1, x2):\n",
        "  return 1*(x1**2) + 2*x2 - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyo9HmQrIRq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67b7472-74dc-41b2-e059-2f142b1c8aa7"
      },
      "source": [
        "def gradient_descent_one_variable(f, initial_x, max_iters=100, lr=0.01, precision = 0.000001, round_to=0.001):\n",
        "  cur_x = initial_x \n",
        "  previous_step_size = 1\n",
        "  iters = 0\n",
        "\n",
        "  for iters in range(max_iters):\n",
        "    print(\"iteration\",iters)\n",
        "    prev_x = cur_x \n",
        "    cur_x = cur_x - lr * f(prev_x) \n",
        "    previous_step_size = abs(cur_x - prev_x)\n",
        "    \n",
        "    if previous_step_size <= precision :\n",
        "      print(\"Converged with\", x.numpy())\n",
        "      return cur_x\n",
        "\n",
        "  print(\"Exited with\", cur_x)\n",
        "  return cur_x\n",
        "      \n",
        "      \n",
        "def tf_gradient_descent_one_variable(f, initial_x, max_iters=1000, lr=0.01, precision = 0.001, optimizer=tf.keras.optimizers.SGD):\n",
        "  x = tf.Variable(1.0*initial_x)\n",
        "  opt = optimizer(learning_rate=lr)\n",
        "  prev_x = x.numpy()\n",
        "  \n",
        "  for i in range(max_iters):\n",
        "    \n",
        "    # https://medium.com/analytics-vidhya/3-different-ways-to-perform-gradient-descent-in-tensorflow-2-0-and-ms-excel-ffc3791a160a\n",
        "    # method 2\n",
        "    with tf.GradientTape() as tape:\n",
        "      y = f(x)\n",
        "    grads = tape.gradient(y, [x])\n",
        "    processed_grads = [g for g in grads]\n",
        "    grads_and_vars = zip(processed_grads, [x])\n",
        "    opt.apply_gradients(grads_and_vars)\n",
        "    previous_step_size = abs(x.numpy() - prev_x)\n",
        "    \n",
        "    prev_x = x.numpy()\n",
        "    if previous_step_size <= precision :\n",
        "      print(\"Converged with\", x.numpy())\n",
        "      return x.numpy()\n",
        "\n",
        "  print(\"Exited with\", x.numpy())\n",
        "  return x.numpy()\n",
        "\n",
        "def tf_gradient_descent_n_variables(f, initial_variables, max_iters=1000, lr=0.01, precision = 0.001, optimizer=tf.keras.optimizers.SGD):\n",
        "  X = [ tf.Variable(1.0* variable) for variable in initial_variables ]\n",
        "  opt = optimizer(learning_rate=lr)\n",
        "  \n",
        "  for i in range(max_iters):\n",
        "    with tf.GradientTape() as tape:\n",
        "      y = f(*X)  # <=> X.unpack()\n",
        "    grads = tape.gradient(y, X)\n",
        "    processed_grads = [g for g in grads]\n",
        "    grads_and_vars = zip(processed_grads, X)\n",
        "    opt.apply_gradients(grads_and_vars)\n",
        "    \n",
        "  variables = [v.numpy() for v in X]\n",
        "  print(\"Converged with: \", variables)\n",
        "  return variables\n",
        "\n",
        "\n",
        "print(\"\\nMinima of y= x + 2*z - 1\")\n",
        "minimum = tf_gradient_descent_n_variables(f2, [5, 0], lr=0.1, precision=0.001)\n",
        "\n",
        "print(\"\\nMinima of y=x²\")\n",
        "minimum = tf_gradient_descent_one_variable(f, 5, lr=0.1, precision=10**-8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Minima of y= x + 2*z - 1\n",
            "Converged with:  [0.0, -199.9981]\n",
            "\n",
            "Minima of y=x²\n",
            "Converged with 3.6185043e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM3jbwc7rGgV"
      },
      "source": [
        "class GradientDescent():\n",
        "  def __init__(self, X, y):\n",
        "    self.X = np.array(X)\n",
        "    self.y = np.array(y)\n",
        "    self.weights = [1.0] + [1.0 for _ in X[0] ]\n",
        "    \n",
        "\n",
        "  def __call__(self, X):\n",
        "    return self.predict(X)\n",
        "\n",
        "  def predict(self, X):\n",
        "    assert len(X) == len(self.weights) - 1\n",
        "    X = X\n",
        "    return sum(i[0] * i[1] for i in zip(X, self.weights))\n",
        "\n",
        "  def loss(self, weights):\n",
        "    predictions = []\n",
        "    i = 0\n",
        "    for x in self.X:\n",
        "      x = [1.0] + x\n",
        "      predictions.append(sum(i[0] * i[1] for i in zip(x, weights)) )\n",
        "    \n",
        "    MAE = 0\n",
        "    for i in range(len(predictions)):\n",
        "      MAE += abs(predictions[i] - self.y[i] )\n",
        "    return MAE\n",
        "    \n",
        "\n",
        "  def train(self, max_iters=100, lr=0.01, epochs=2, precision = 0.001, optimizer=tf.keras.optimizers.SGD):\n",
        "    opt = optimizer(learning_rate=lr)\n",
        "    X = [tf.Variable(1.0* variable) for variable in self.weights ]\n",
        "    # Compute the gradients for a list of variables.\n",
        "    for i in range(max_iters):\n",
        "      with tf.GradientTape() as tape:\n",
        "        y = self.loss(X) # has to be a one line loss function...\n",
        "      grads = tape.gradient(y, X)\n",
        "      # Process the gradients\n",
        "      processed_grads = [g for g in grads]\n",
        "      # Ask the optimizer to apply the processed gradients.\n",
        "      opt.apply_gradients(\n",
        "          (grad, var) \n",
        "          for (grad, var) in zip(processed_grads, X)\n",
        "          if grad is not None\n",
        "          )\n",
        "      variables = [ v.numpy() for v in X ]\n",
        "      \n",
        "\n",
        "      self.weights = variables\n",
        "    return variables\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKC5JbE7N74M"
      },
      "source": [
        "## Question 2: optimizers\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bts55U-5HP8y",
        "outputId": "14d2f9d0-e049-4f1c-e6fe-d8772ea91f27"
      },
      "source": [
        "print(\"Adam\")\n",
        "minimum = tf_gradient_descent_one_variable(f, 5, lr=0.1, precision=10**-8, optimizer=tf.keras.optimizers.Adam)\n",
        "print(\"RMSprop\")\n",
        "minimum = tf_gradient_descent_one_variable(f, 5, lr=0.1, precision=10**-8, optimizer=tf.keras.optimizers.RMSprop)\n",
        "print(\"Momentum\")\n",
        "minimum = tf_gradient_descent_one_variable(f, 5, lr=0.1, precision=10**-8)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam\n",
            "Converged with -2.0924533e-06\n",
            "RMSprop\n",
            "Converged with 4.97395e-10\n",
            "Momentum\n",
            "Converged with 3.6185043e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpPN6zHHTYii"
      },
      "source": [
        "## 2. I implement in order to understand"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrsdDDHkZWei"
      },
      "source": [
        "# perceptron from tp1\n",
        "def perceptron(x, y, max_iterations=3000):\n",
        "  w = np.zeros((1,2))\n",
        "  p = np.zeros((1,2))\n",
        "  for it in range(max_iterations):\n",
        "        for X, Y in zip(x, y) :\n",
        "            if  Y * np.inner(X, w) <= 0 : \n",
        "                p = w\n",
        "                w = w + np.multiply(X, Y)\n",
        "        if (w == p).all() :\n",
        "            return (w.tolist(), True)\n",
        "  return (w.tolist(), it>=max_iterations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1UOEQYpaS6F"
      },
      "source": [
        "### 2.1 Toy data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xVNiX-vOs9S"
      },
      "source": [
        "def generate_dataset(sigma1, sigma2, test_size=0.2):\n",
        "  mu1 = [-1, 0]\n",
        "  mu2 = [1, 0]\n",
        "  \n",
        "  cov1 = [ [sigma1 , 0 ], \n",
        "           [0 , sigma1 ] \n",
        "          ]\n",
        "\n",
        "  cov2 = [  [ sigma2 , 0 ], \n",
        "            [ 0 , sigma2 ] \n",
        "          ] \n",
        "  x1 = multivariate_normal(mu1, cov1, 125)\n",
        "  x2 = multivariate_normal(mu2, cov2, 125)\n",
        "  dataset = pd.DataFrame({\n",
        "      \"x\": x1.tolist() + x2.tolist(),\n",
        "      \"y\": [-1 for _ in range(125)] + [1 for _ in range(125)]\n",
        "  })\n",
        "\n",
        "  return train_test_split(dataset.get(\"x\"), dataset.get(\"y\"), test_size=test_size, random_state=42)\n",
        "\n",
        "# use:\n",
        "train_x, test_x, train_y, test_y = generate_dataset(sigma1=0.1, sigma2=0.01)\n",
        "dataset_x = (train_x, test_x)\n",
        "\n",
        "\n",
        "learning_rate = 0.01\n",
        "max_iterations = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WEaYSHyM0tn",
        "outputId": "7b57cd38-8432-411d-8296-8c9fd0a1e09f"
      },
      "source": [
        "grad = GradientDescent(train_x.tolist(), train_y.tolist())\n",
        "%time w = grad.train(lr=learning_rate, max_iters=max_iterations)\n",
        "\n",
        "print(\"Gradient descent converges with: \", w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 42s, sys: 1.96 s, total: 2min 44s\n",
            "Wall time: 2min 44s\n",
            "Gradient descent converges with:  [1.4101685, -0.028953252, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJy8emuanf8S",
        "outputId": "169c7024-7026-4df7-d4aa-6b69b8e0827d"
      },
      "source": [
        "%time w, converges = perceptron(train_x, train_y, max_iterations=max_iterations)\n",
        "\n",
        "if converges :\n",
        "  print(\"Perceptron converged: \")\n",
        "print(\"minima found: \", w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.3 s, sys: 102 ms, total: 1.4 s\n",
            "Wall time: 1.32 s\n",
            "minima found:  [[1.0618208986391857, -0.0266751717826906]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICLj7PztYc2c"
      },
      "source": [
        "## 2.2  Real data: IRIS dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0XRrKx0T2gt"
      },
      "source": [
        "# import some data to play with\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "v3PC3QUimwcg",
        "outputId": "b4264d6d-661d-49f2-cdb3-b7bac5ea1069"
      },
      "source": [
        "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris['feature_names'] + ['target'])\n",
        "\n",
        "iris_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.057333</td>\n",
              "      <td>3.758000</td>\n",
              "      <td>1.199333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.435866</td>\n",
              "      <td>1.765298</td>\n",
              "      <td>0.762238</td>\n",
              "      <td>0.819232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal length (cm)  sepal width (cm)  ...  petal width (cm)      target\n",
              "count         150.000000        150.000000  ...        150.000000  150.000000\n",
              "mean            5.843333          3.057333  ...          1.199333    1.000000\n",
              "std             0.828066          0.435866  ...          0.762238    0.819232\n",
              "min             4.300000          2.000000  ...          0.100000    0.000000\n",
              "25%             5.100000          2.800000  ...          0.300000    0.000000\n",
              "50%             5.800000          3.000000  ...          1.300000    1.000000\n",
              "75%             6.400000          3.300000  ...          1.800000    2.000000\n",
              "max             7.900000          4.400000  ...          2.500000    2.000000\n",
              "\n",
              "[8 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G1FZ17tmxs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13ccdbd-8b1d-4425-9dc5-e455354b99e8"
      },
      "source": [
        "encoder =  LabelEncoder()\n",
        "\n",
        "iris_X = iris_df.iloc[:,0:3].values\n",
        "iris_y = encoder.fit_transform(iris_df.iloc[:,4].values)\n",
        "\n",
        "print(\"input: {}\\noutput shape:{}\".format(iris_X.shape, iris_y.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: (150, 3)\n",
            "output shape:(150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWvlucY8VB64",
        "outputId": "484dd11c-4933-4c36-ea22-bd827e85e6e9"
      },
      "source": [
        "print(set(iris_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2PEk84OVn7h"
      },
      "source": [
        "### This is a multi class classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVlvROmIVhd8"
      },
      "source": [
        "y_dummies = pd.get_dummies(iris_y).values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_X, y_dummies, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5YY7BWfWJ1U"
      },
      "source": [
        "### Model 1: Simple, plain, unimpressive neural net (Linear correlation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAkLYIPtV0qA"
      },
      "source": [
        "simple_NN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(3)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NrUEu6nWVR5"
      },
      "source": [
        "### Model 2: Neural net with hidden layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpcLR5aDWTs6"
      },
      "source": [
        "more_cmplx_NN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(3)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnx8ojTTWpQx"
      },
      "source": [
        "### Model 3: One layer neural net with more neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXVvqgs1WgKc"
      },
      "source": [
        "thicc_NN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKnpDiErXdvX"
      },
      "source": [
        "### Model 4: One layer neural net with softmax instead of relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-D43mDtXjIV"
      },
      "source": [
        "softmax_NN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(512, activation='softmax'),\n",
        "    tf.keras.layers.Dense(3)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGf6vqNoaSgT"
      },
      "source": [
        "# Model 5: Everything combined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vi-ED0jaWG0"
      },
      "source": [
        "chad_NN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(512, activation='softmax'),\n",
        "    tf.keras.layers.Dense(3)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pHwt32vW4Lc"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvSltXcHXJQo"
      },
      "source": [
        "# Evaluation method for the models:\n",
        "def evaluate(model, lr=0.01, opt='rmsprop', loss='categorical_crossentropy'):\n",
        "  model.compile(optimizer=opt,\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "  \n",
        "  print('Test loss:', loss)\n",
        "  print('Test accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Eqq3wQWZ3kS"
      },
      "source": [
        "#### Experiment 1: \n",
        "The learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EzzJw2bW1U-",
        "outputId": "b94e8cdb-4621-4e7e-e8ac-7dfbde28b637"
      },
      "source": [
        "for learning_rate in [0.1, 0.01, 0.001]:\n",
        "  print(\"Learning rate: \",learning_rate)\n",
        "  evaluate(simple_NN, lr=learning_rate)\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.1\n",
            "Test loss: 1.1233361959457397\n",
            "Test accuracy: 0.3333333432674408\n",
            "\n",
            "Learning rate:  0.01\n",
            "Test loss: 1.1233361959457397\n",
            "Test accuracy: 0.3333333432674408\n",
            "\n",
            "Learning rate:  0.001\n",
            "Test loss: 1.1233361959457397\n",
            "Test accuracy: 0.3333333432674408\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FVEQVziaAZi"
      },
      "source": [
        "#### Experiment 2: \n",
        "The number of layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWXeGjDkX2eK",
        "outputId": "8dc716b9-43b1-4d1c-e67c-5525c6c86fe1"
      },
      "source": [
        "print(\"1 layer:\")\n",
        "evaluate(simple_NN)\n",
        "print(\"\\n2 layers:\")\n",
        "evaluate(more_cmplx_NN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 layer:\n",
            "Test loss: 1.1233361959457397\n",
            "Test accuracy: 0.3333333432674408\n",
            "\n",
            "2 layers:\n",
            "Test loss: 1.2815628051757812\n",
            "Test accuracy: 0.3333333432674408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJNCFcGZaLVD"
      },
      "source": [
        "#### Experiment 3: \n",
        "The number of neurons in each layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFMylk1CaJse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f77ae4-d3c2-451b-f441-6024285c1388"
      },
      "source": [
        "print(\"1 layer - 128 neurons:\")\n",
        "evaluate(simple_NN)\n",
        "print(\"\\n1 layers - 512 neurons:\")\n",
        "evaluate(thicc_NN)\n",
        "print(\"\\n2 layers - 256 and 512 neurons:\")\n",
        "evaluate(chad_NN)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 layer - 128 neurons:\n",
            "Test loss: 1.1233361959457397\n",
            "Test accuracy: 0.3333333432674408\n",
            "\n",
            "1 layers - 512 neurons:\n",
            "Test loss: 5.262626647949219\n",
            "Test accuracy: 0.36666667461395264\n",
            "\n",
            "2 layers - 256 and 512 neurons:\n",
            "Test loss: 4.872152805328369\n",
            "Test accuracy: 0.30000001192092896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMWUvLfIaw25"
      },
      "source": [
        "#### Experiment 4: \n",
        "The cost function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bYwYJ0eatYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0657d705-7f1e-4678-a058-3c174c53c28c"
      },
      "source": [
        "print(\"\\n1 layer - 512 neurons - Categorical crossentropy:\")\n",
        "evaluate(thicc_NN, loss='categorical_crossentropy')\n",
        "print(\"\\n1 layer - 512 neurons - Categorical cringe:\")\n",
        "evaluate(thicc_NN, loss='categorical_hinge')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1 layer - 512 neurons - Categorical crossentropy:\n",
            "Test loss: 5.262626647949219\n",
            "Test accuracy: 0.36666667461395264\n",
            "\n",
            "1 layer - 512 neurons - Categorical cringe:\n",
            "Test loss: 1.2538719177246094\n",
            "Test accuracy: 0.36666667461395264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0O67WXdbrVu"
      },
      "source": [
        "  #### Experiment 5: \n",
        "  the activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMGe6TsNbNjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f6a37a-e1d1-4ba4-a57a-93ec8c612370"
      },
      "source": [
        "print(\"\\n1 layer - 512 neurons - Relu:\")\n",
        "evaluate(thicc_NN)\n",
        "print(\"\\n1 layer - 512 neurons - Softmax:\")\n",
        "evaluate(softmax_NN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1 layer - 512 neurons - Relu:\n",
            "Test loss: 5.262626647949219\n",
            "Test accuracy: 0.36666667461395264\n",
            "\n",
            "1 layer - 512 neurons - Softmax:\n",
            "Test loss: 1.2193207740783691\n",
            "Test accuracy: 0.36666667461395264\n"
          ]
        }
      ]
    }
  ]
}