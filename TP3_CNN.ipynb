{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning Practical Assignment #3:\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "\n",
    "Linear Classifier : Fully connected networks\n",
    "Binome : Zeineb Medallel et Mayssa Ben Mefteh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "names = iris['target_names']\n",
    "feature_names = iris['feature_names']\n",
    "\n",
    "# One hot encoding\n",
    "enc = OneHotEncoder()\n",
    "Y = enc.fit_transform(y[:, np.newaxis]).toarray()\n",
    "\n",
    "# Scale data to have mean 0 and variance 1 (for convergence of the neural network) \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the data set into training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "X_scaled, Y, test_size=0.5, random_state=2)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "n_classes = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_custom_model(input_dim, output_dim, nodes, n=1, name='model'):\n",
    "    def create_model():\n",
    "        # creating the  model\n",
    "        model = Sequential(name=name)\n",
    "        for i in range(n):\n",
    "            model.add(Dense(nodes, input_dim=input_dim, activation='relu'))\n",
    "        model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "        # creating the model\n",
    "        model.compile(loss='categorical_crossentropy', \n",
    "                      optimizer='adam', \n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    return create_model\n",
    "\n",
    "models = [create_custom_model(n_features, n_classes, 8, i, 'model_{}'.format(i)) \n",
    "          for i in range(1, 4)]\n",
    "\n",
    "for create_model in models:\n",
    "    create_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "from keras.callbacks import TensorBoard\n",
    "history_dict = {}\n",
    "# TensorBoard Callback\n",
    "cb = TensorBoard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing fully connected dataset\n",
    "In this segment we are using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (3, 12)                   48        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (3, 5)                    65        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (3, 3)                    18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "#initialisation of the model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Sample code to create a fully connected network\n",
    "\n",
    "model.add(layers.Dense(12, activation=\"relu\"))\n",
    "model.add(layers.Dense(5, activation=\"relu\"))\n",
    "model.add(layers.Dense(3))\n",
    "\n",
    "# Call model on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17414af1a00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling the keras model\n",
    "model.compile( loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#fitting the keras model\n",
    "model.fit(x, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Mnist dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing librairies \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten, Activation,MaxPool2D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset \n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data  (60000, 28, 28) - (60000,)\n",
      "Test data  (10000, 28, 28) - (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Shape of the data \n",
    "print('Training data ',X_train.shape,'-',y_train.shape)\n",
    "print('Test data ',X_test.shape,'-',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Viewing the data \n",
    "plt.imshow(X_train[0],cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape data into a long vector \n",
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling data \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical encoding\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Let's see what happened to categorical variable \n",
    "print(y_train[0])\n",
    "print(y_train_cat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fully Connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 256)               200960    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 304,106\n",
      "Trainable params: 304,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Fully Connected Architecture \n",
    "# Here we used a total of three hidden layers with ‘relu’ activation function apart from input and output layer\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "## Printing model summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.3420 - accuracy: 0.8987 - val_loss: 0.2000 - val_accuracy: 0.9384\n",
      "Epoch 2/5\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1242 - accuracy: 0.9626 - val_loss: 0.1167 - val_accuracy: 0.9647\n",
      "Epoch 3/5\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.0806 - accuracy: 0.9756 - val_loss: 0.1135 - val_accuracy: 0.9679\n",
      "Epoch 4/5\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9814 - val_loss: 0.1040 - val_accuracy: 0.9727\n",
      "Epoch 5/5\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9866 - val_loss: 0.1211 - val_accuracy: 0.9679\n"
     ]
    }
   ],
   "source": [
    "# Fitting fully connected model with validation_split as 0.3\n",
    "h = model.fit(X_train, y_train_cat, batch_size=128, epochs=5, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualising Training and Validation Accuracy\n",
    "plt.plot(h.history['accuracy'])\n",
    "plt.plot(h.history['val_accuracy'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On training the fully connected model for five epochs with a batch size of 128, and validation split value set to 0.3 we got training accuracy of 98.6% and validation accuracy of 96.07%. Moreover, after 2nd epoch, we can visualize how train and validation accuracy tends to move wide apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.9708\n",
      "Test Accuracy 97.08\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(X_test, y_test_cat)[1]\n",
    "print(\"Test Accuracy\",np.round((test_accuracy)*100,2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On test data with 10,000 images accuracy for the fully connected neural network is 97%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping independent variable for CNN\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 32)          9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2592)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 32)                82976     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,122\n",
      "Trainable params: 102,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN architecture\n",
    "\n",
    "# In this model we added 3 convolutional layers with activation as ‘relu’ and a max pool layer after the first convolutional layer.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "With CNN the differences you can notice in summary are Output shape and number of parameters. As compared to the fully connected neural network model the total number of parameters is too less i.e. 0.1 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "329/329 [==============================] - 20s 60ms/step - loss: 0.2801 - accuracy: 0.9147 - val_loss: 0.1484 - val_accuracy: 0.9561\n",
      "Epoch 2/5\n",
      "329/329 [==============================] - 19s 59ms/step - loss: 0.0729 - accuracy: 0.9777 - val_loss: 0.0770 - val_accuracy: 0.9751\n",
      "Epoch 3/5\n",
      "329/329 [==============================] - 20s 62ms/step - loss: 0.0478 - accuracy: 0.9854 - val_loss: 0.0565 - val_accuracy: 0.9833\n",
      "Epoch 4/5\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 0.0516 - val_accuracy: 0.9856\n",
      "Epoch 5/5\n",
      "329/329 [==============================] - 19s 57ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 0.0534 - val_accuracy: 0.9856\n"
     ]
    }
   ],
   "source": [
    "h1=model.fit(X_train, y_train_cat, batch_size=128,epochs=5, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0403 - accuracy: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.040309593081474304, 0.9872000217437744]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On test data with 10,000 images, accuracy for the fully connected neural network is 98.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualising Training and Validation Accuracy\n",
    "plt.plot(h1.history['accuracy'])\n",
    "plt.plot(h1.history['val_accuracy'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "unlike the fully connected model, we can visualize train and validation accuracy do not tend to move as wide apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "fully connected networks make no assumptions about the input they tend to perform less and aren’t good for feature extraction while on the other hand CNNs are trained to identify and extract the best features from the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### using the digit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Summary -------------------\n",
      "Train: X=(60000, 28, 28), y=(60000,)\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    }
   ],
   "source": [
    "# cnn model with batch normalization for mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "# loading the dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "# summary\n",
    "print(\"------------------------------Summary -------------------\")\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "# reshaping the dataset to have a single channel\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\n",
    "# one hot encode target values\n",
    "trainY = keras.utils.to_categorical(trainY)\n",
    "testY = keras.utils.to_categorical(testY)\n",
    "\n",
    "# loading training and testing dataset\n",
    "def load_dataset():\n",
    "    # loading dataset\n",
    "    (trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "    # reshaping dataset to have a single channel\n",
    "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "    # one hot encode target values\n",
    "    trainY = keras.utils.to_categorical(trainY)\n",
    "    testY = keras.utils.to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # converting from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalizing to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    return train_norm, test_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compiling the model\n",
    "    opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing VGG16 architecture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = fetch_olivetti_faces()\n",
    "\n",
    "\n",
    "X = faces.data\n",
    "y = faces.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the convolution    \n",
    "→ 2 x convolution layer of 64 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 2 x convolution layer of 128 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 3 x convolution layer of 256 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 3 x convolution layer of 512 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n",
    "\n",
    "→ 3 x convolution layer of 512 channel of 3x3 kernal and same padding\n",
    "\n",
    "→ 1 x maxpool layer of 2x2 pool size and stride 2x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the model by specifying that the model is a sequential model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding relu so that all the negative values are not passed to the next layer\n",
    "\n",
    "model.add( Dense (12 , input_dim =faces.data.shape[1] , activation ='relu'))\n",
    "model.add( Dense (5 , activation ='relu'))\n",
    "model.add( Dense (40, activation ='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model from keras.optimizers \n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 112, 112, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 7, 7, 12)          6156      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 7, 7, 5)           65        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 7, 7, 40)          240       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,721,149\n",
      "Trainable params: 14,721,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Model\n",
    "\n",
    "hist=  model.fit(X_train , epochs =50 , batch_size =int(X.shape[1] / 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Fine-tuning a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm # for progress bar\n",
    "\n",
    "# Libraries for TensorFlow\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow import keras\n",
    "\n",
    "# Library for Transfer Learning\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 3), (10000, 28, 28, 3))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "\n",
    "(xtrain,ytrain),(xtest,ytest)= keras.datasets.mnist.load_data()\n",
    "\n",
    "#Convert the images into 3 channels\n",
    "\n",
    "xtrain=np.dstack([xtrain] * 3)\n",
    "xtest=np.dstack([xtest]*3)\n",
    "xtrain.shape,xtest.shape\n",
    "xtrain = xtrain.reshape(-1, 28,28,3)\n",
    "xtest= xtest.reshape (-1,28,28,3)\n",
    "xtrain.shape,xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 48, 48, 3), (10000, 48, 48, 3))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "\n",
    "xtrain = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtrain])\n",
    "xtest = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in xtest])\n",
    "#train_x = preprocess_input(x)\n",
    "xtrain.shape, xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Implementing VGG16\n",
    "\n",
    "# we are using VGG16 for transfer learnin here. So we have imported it\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# initializing model with weights='imagenet'i.e. we are carring its original weights\n",
    "model_vgg16=VGG16(weights='imagenet')\n",
    "\n",
    "# display the summary to see the properties of the model\n",
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# let us prepare our input_layer to pass our image size. default is (224,224,3). we will change it to (48,48,3)\n",
    "input_layer=layers.Input(shape=(48,48,3))\n",
    "\n",
    "# initialize the transfer model VGG16 with appropriate properties per our need.\n",
    "\n",
    "model_vgg16=VGG16(weights='imagenet',input_tensor=input_layer,include_top=False)\n",
    "\n",
    "# See the summary of the model with our properties.\n",
    "model_vgg16.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FC vs CNN "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "•A fully connected neural network consists of a series of fully connected layers that connect every neuron in one layer to every neuron in the other layer.\n",
    "•CNN architectures make the explicit assumption that the inputs are images, which allows encoding certain properties into the model architecture.\n",
    "•With CNN the differences you can notice in summary are Output shape and number of parameters. As compared to the fully connected neural network model the total number of parameters is too less i.e. 0.1 million.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
